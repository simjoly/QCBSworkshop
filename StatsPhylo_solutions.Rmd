---
title: "An introduction to phylogenetic comparative methods (in R)"
author: "Simon Joly"
date: "Fall 2019"
output:
  html_document:
    highlight: haddock
    theme: united
    toc: yes
    toc_depth: 2
  pdf_document:
    highlight: haddock
    toc: yes
    toc_depth: 2
---

----


# Preface

This document consist in an introduction of the comparative methods. It contains theory as well as practical examples in R on Phylogenetic Generalized Least Squares (PGLS) and Phylogenetic Mixed Models (PMM). It was developed for a full day workshop that consists in short presentations followed by R exercises. Note that the present document should pretty much stand by itself because most of the theory given in the presentations are incorporated into the theory sections. Therefore, this document should contain all the necessary information to understand the examples.

I assume that the readers are "reasonably" familiar with R as well as with linear regression and its assumptions. There are a lot of good R introductory tutorials on the web and for linear models, Zuur et al. (2007) provide a good introduction. Good introductions to model fitting in R are Dolph Schluter's [webpage](https://www.zoology.ubc.ca/~schluter/R/fit-model/) and the [QCBS workshops](http://qcbs.ca/wiki/r_workshop4).

## Getting ready for the R examples

To perform the examples of this document, you will need to have the R software installed on your computer. I also recommend that you install RStudio that facilitates interactions between scripts and the console.

For this specific tutorial, we will need to load the following R packages.

```{r "load libraries", message=FALSE, warning=FALSE}
library(nlme)
library(ape)
library(RColorBrewer)
library(ggplot2)
library(MCMCglmm)
```

To execute the code in R, you can just copy and paste the code in the boxes in your R console. This will replicate the analyses presented here. 

If some of the packages above are not yet installed on your computer (i.e., you get error messages when trying to load them), you will have to install them using the function `install.packages()`. You only have to install them once.

```{r "install libraries", message=FALSE, warning=FALSE, eval=FALSE}
install.packages('nlme')
install.packages('ape')
install.packages('RColorBrewer')
install.packages('ggplot2')
install.packages('MCMCglmm')
```

Once this is done, you can reload the packages using the `library()` function. Also note that if you are using both the packages `nlme` and `ape`, `nlme` should be loaded first. If you don't do this, you might get errors; you could then restart R and start over.

I first introduce comparative methods more generally before introducing Phylogenetic Generalized Least Squares (PGLS), and I finish with slightly more advanced topics such as model testing with PGLS.


## Working with github

All the data of the workshop are deposited in a github repository. The easiest way to access them is to go to the workshop directory and clone it on your computer. [Workshop repository](http://www.github.com/simjoly/QCBSworkshop).

Once you have cloned the repository, you need to open R (R studio) and set the working directory to the repository folder ("/QCBSworkshop"). In RStudio, to change the working directory, you choose `>Session>Set Working directory>Choose Directory`.You are now ready to do the exercises.


# An introduction to Phylogenetic Comparative Methods

Phylogenetic comparative methods were introduced by Joseph Felsenstein in 1985. The idea of phylogenetic comparative methods was to correct for the non-independence of species in statistical tests because of their shared evolutionary histories. Indeed, two species may look similar not because they live in the same environment but because they are closely related. For instance, considering the following angiosperm phylogeny.

```{r "AngiospermTree", echo=FALSE, fig.height=3, fig.width=4, fig.align='center'}
require(ape)
landplants.newick <- "(Marchantia:0.033817,(Lycopodium:0.040281,((Equisetum:0.048533,Osmunda:0.033640,Asplenium:0.036526):0.011806,(((Cycas:0.009460,Zamia:0.018847):0.005021,Ginkgo:0.014702,((Pinus:0.021500,(Podocarpac:0.015649,Taxus:0.021081):0.006473):0.002448,(Ephedra:0.029965,(Welwitsch:0.011298,Gnetum:0.014165):0.006883):0.016663):0.006309):0.010855,(Nymphaea:0.016835,(Saururus:0.019902,Chloranth:0.020151,((Araceae:0.020003,(Palmae:0.006005,Oryza:0.031555):0.002933):0.007654,Acorus:0.038488):0.007844,(Calycanth:0.013524,Lauraceae:0.035902):0.004656,((Magnolia:0.015119,Drimys:0.010172):0.005117,(Ranunculus:0.029027,(Nelumbo:0.006180,Platanus:0.002347):0.003958,(Buxaceae:0.013294,(Pisum:0.035675,(Fagus:0.009848,Carya:0.008236):0.001459):0.001994,(Ericaceae:0.019136,Solanaceae:0.041396):0.002619):0.004803):0.006457):0.002918):0.007348,Austrobail:0.019265,Amborella:0.019263):0.003527):0.021625):0.012469):0.019372);"
landplants.tree <- read.tree(text=landplants.newick)
species.to.keep <- c("Lycopodium","Asplenium","Cycas","Ginkgo","Pinus",
                     "Taxus","Amborella","Oryza","Platanus","Pisum","Fagus")
species.to.exclude <- landplants.tree$tip.label[!(landplants.tree$tip.label %in% 
                                                    species.to.keep)]
reduced.landplants.tree <- drop.tip(landplants.tree,species.to.exclude)
reduced.landplants.chronos <- chronos(reduced.landplants.tree,quiet=TRUE)
op <- par(mar=c(1,1,1,1))
plot(reduced.landplants.chronos, label.offset=0.02, cex=0.9)
par(op)
```

It is clear that *Fagus* (beech) and *Pisum* (pea) are more likely to share similar characteristics compared to *Asplenium* (a fern), because they share a more recent common ancestor. In other words, their evolutionary histories are shared over a longer period than with *Asplenium*. As such, they have more chance to have more similar traits (and in fact they do). For instance, take two characters, ovule and fertilization type, within this group.

```{r "AngiospermsWithCharacters", echo=FALSE, warning=FALSE, fig.height=4, fig.width=4, fig.align='center'}
require(RColorBrewer)
enclosed.ovules <- as.factor(c("no","no","no","no","no","no","yes","yes","yes","yes","yes"))
double.fertilization <- as.factor(c("no","no","no","no","no","no","yes","yes","yes","yes","yes"))
ColorPalette1 <- brewer.pal(n = 4, name = "Dark2")
op <- par(mar=c(5,1,1,1))
plot(reduced.landplants.chronos, label.offset=0.15, cex=0.9)
tiplabels(pch=21,bg=ColorPalette1[1:2][enclosed.ovules],col="black",cex=1,adj=0.55)
tiplabels(pch=21,bg=ColorPalette1[3:4][double.fertilization],col="black",cex=1,adj=0.6)
par(xpd=TRUE)
legend(0,0,legend=c("Ovules:nude","Ovules:enclosed","Simple fertilization","Double fertilization"),col=ColorPalette1,pch=20,bty="n",cex=1,pt.cex=1.5,ncol=2)
par(op) #reset graphical parameters to defaults
```

Ignoring the phylogeny, we might be tempted to see a strong correlation between these two characters. Indeed, the states between the two characters show a perfect correspondence. Using standard contingency table statistics, we could do a Fisher exact test:

```{r "Fisher test", warning=FALSE}
fisher.test(matrix(c(5,0,0,6),ncol=2))
```

The test suggests that the assotiation is highly significant. However, we know that the comparisons made are not completely independent. Actually, both characters evolved only once, and this along the same branch.

A more appropriate question would be "what is the probability that two characters evolved along the same branch?". This can be calculated using a contingency table, but this time taking the observations along the branches of the phylogeny. In the example, there are 18 branches and the two characters evolved only once and on the same branch. The contingency table when considering the changes along the branches looks like this:

```{r contingency_table, echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)
tabl <- matrix(c(1,0,0,17),nrow=2)
rownames(tabl) <- c("Change in trait 1","No change in trait 1")
colnames(tabl) <- c("Change in trait 2","No change in trait 2")
tabl %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "left") %>%
  column_spec(1, bold = TRUE)
```

With this table, Fisher's exact test will give the following result:

```{r "Fisher test phylogenetic", warning=FALSE}
fisher.test(matrix(c(1,0,0,17),ncol=2))
```

You can see that the result is no longer significant. While this approach is correct, more powerful comparative methods have been developped. One useful and powerful approach is the Phylogenetic Generalized Least Squares (PGLS) and it is the one that will be introduced next. But first, let's do some revision and look briefly at the standard regression to better understand PGLS.


# The linear regression model

## Theory

The linear model has the following form:

$$\textbf{y} = \alpha + \beta \textbf{x} + \textbf{e}$$

$\textbf{y}$ is the response (or dependent) variable, $\textbf{x}$ is the explanatory (or independent) variable, and $\textbf{e}$ represent the residuals or in other words the information unexplained by the model. For a simple regression model, this represents the distance along the y axis between the observations and the regression line. The parameters $\alpha$ and $\beta$ are the population intercept and slope, respectively, and are unknown. In practive, you take a sample of size $N$ and you get estimates $\hat{\alpha}$ and $\hat{\beta}$ for the intercept and the slope, respectively. When the linear regression is standardly fitted using ordinary least squares (OLS), the residuals $\textbf{e}$ are assumed to be normally distributed with expectation $0$ and variance $\sigma^2$. In mathematic terms, $\textbf{e} \sim N(0,\sigma^2)$.

Obtaining reliable estimates with a linear regression implies that the data meets reveral assumptions, amongst which are normality, homogeneity, fixed $X$, independence, and correct model specification. We won't review all these here, but we will focus on one that is often violated when the data are phylogenetically structured, which is **independence**. This assumption is important as a lack of independence invalidates important tests such as the F-test and the t-test.

You get a violation of independece when the $\textbf{y}_i$ value at $\textbf{x}_i$ is influenced by other $\textbf{x}_i$. Obviously, this can happen with phylogenetically structured data as a response variable is be more likely to react similarly to an explanatory variable if they are closely related species. In other words, the y value for a species in not completely independent from the y value os a closely related species: theirs y are correlated. We'll illustrate this in an example below.

## Practice

To provide pratical examples in this workshop, we will use a dataset of tree functional traits from the province of Quebec, published by [Paquette, Joly and Messier (2015)](http://onlinelibrary.wiley.com/doi/10.1002/ece3.1456/abstract). The dataset consists in a number of plant functional traits and in a molecular phylogeny built using the plant barcode markers *rbc*L and *mat*K. The dataset you need to run the examples are already in the /data/ folder of the github repository. However, you can also download them by clicking on the links below.

[seedplants.tre](http://www.plantevolution.org/data/seedplants.tre)

[seedplants.csv](http://www.plantevolution.org/data/seedplants.csv)

Before analysing the data, we will start by opening the data and the phylogenetic tree and clean them to keep only the species present in both the tree and the trait table. This is necessary because some additional species were included in the phylogenetic tree reconstruction to get a good topology.

```{r "Open_seed_plant_data", warning=FALSE}
require(ape)
# Open the documents; it assumes that you are in the main directory of the workshop folder
seedplantstree <- read.nexus("./data/seedplants.tre")
seedplantsdata <- read.csv2("./data/seedplants.csv")
# Remove species for which we don't have complete data
seedplantsdata <- na.omit(seedplantsdata)
# Remove species in the tree that are not in the data matrix
species.to.exclude <- seedplantstree$tip.label[!(seedplantstree$tip.label %in% seedplantsdata$Code)]
seedplantstree <- drop.tip(seedplantstree,species.to.exclude)
# Remove unnecessary object
rm(species.to.exclude)
```

Now, we can have a look at the data, and then order the plant trait to be in the same order as the species in the tree.

```{r "data ordering"}
# Here is what the loaded data looks like
head(seedplantsdata)
# Order tree to make it nicer when plotting
seedplantstree <- ladderize(seedplantstree, right = FALSE)
# Name the rows of the data.frame with the species codes used as tree labels 
#  and remove the obsolete column with species codes.
rownames(seedplantsdata) <- seedplantsdata$Code
seedplantsdata <- seedplantsdata[,-1]
# Order the data in the same order as the tip.label of the tree. In the present 
#  example, this was already the case, but it is an important step for 
#  any analysis.
seedplantsdata <- seedplantsdata[seedplantstree$tip.label,]
```

Now that the data is ready, let's fit a linear model and try to explain shade tolerance (Shade) of trees using wood density (Wd). In R, a very simple way to do a regression is to use the function 'lm', which stands for linear model. To fit a linear model, you need to tell the `lm` function which variable is the response variable and which one is the explanatory variable. This is done using formulas in the form `Shade ~ Wd`. The variable at the left of the tilde ('~') is the response variable (`Shade`) whereas the explanatory variale (1 or more) are at the right of the tilde.

```{r "Example: non independence", warning=FALSE}
# Fit a linear model using Ordinary Least Squares (OLS)
shade.lm <- lm(Shade ~ Wd, data = seedplantsdata)
# Print the results
summary(shade.lm)
```

You can see that the slope estimate (here the parameter `Wd`) is `r round(shade.lm$coefficient[2],2)` and that is not significant ($p$=`r round(summary(shade.lm)$coefficients[2,4],3)`). The standard descriptive plots obtained with `plot(shade.lm)` show that there is slightly greater variation in the residuals for low fitted values, but these are not extreme. However, another way that the assumption of independence can be violated is if the residuals are phylogenetically correlated. One way to test this is to plot the residuals at the tips of the phylogeny. Let's see what this gives.

```{r "Residuals of lm on phylogeny", fig.align='center'}
# Extract the residuals
shade.res <- residuals(shade.lm)

#
# Plot the residuals beside the phylogeny

# The following command changes the graphical parameters for nicer tree output
op <- par(mar=c(1,1,1,1))
# Vector of colors for the tree plotting
cols <- c("#7570b3","#d95f02")
# The next three commands will plot the tree, then circles that reflect 
#  the residuals values at the tips of the tree, and will finally
#  add a legend.
# The plot command plots the tree and leaves some space to plot the 
#  residuals at the tips with the 'label.offset=0.01' option
plot(seedplantstree,type="p",TRUE,label.offset=0.01,cex=0.5,no.margin=FALSE)
# The next command plots the residuals. the 'bg' option is for the background color. If
#  the residuals are greater than 0 (shade.res>0), it will print the first colour (1) of
#  the 'cols' array and if it is below zero, it prints the second color (2). The the size 
#  of the circle (the 'cex' option) is relative to the absolute value of the residuals 
#  (abs(shade.res). To plot other values, just replace the 'shade.res' vector by another one.
tiplabels(pch=21,bg=cols[ifelse(shade.res>0,1,2)],col="black",cex=abs(shade.res),adj=0.505)
# Print the legend
legend("topleft",legend=c("-2","-1","0","1","2"),pch=21,
       pt.bg=cols[c(1,1,1,2,2)],bty="n",
       text.col="gray32",cex=0.8,pt.cex=c(2,1,0.1,1,2))
# Reset graphical parameters to defaults
par(op) 
```

You can see that in several cases, closely related species tend to have similar residuals (they are of the same color, which means that they are of the same side of the regression slope). This is problematic. Indeed, it shows that the assumption of independence of the ordinary least squares (OLS) regression no longer holds and the statistical tests for the null hypotheses are no longer valid. We will see next how phylogenetic generalized least squares can correct this.

## Challenge 1

In the `seedplantsdata` data frame, there were many different traits. Try to fit a regression of tree shade tolerance (`shade`) on the seed mass (`Sm`). In other words, test if shade tolerance can be explained by the seed mass of the trees. Then, try to see if the residuals are phylogenetically correlated.

```{r "Challenge 1", warning=FALSE, echo=TRUE, eval=TRUE}
# Fit a linear model using Ordinary Least Squares (OLS)
Sm.lm <- lm(Shade ~ Sm, data = seedplantsdata)
# Get the results
summary(Sm.lm)
# Extract the residuals
Sm.res <- residuals(Sm.lm)
# Plot the residuals beside the phylogeny
op <- par(mar=c(1,1,1,1))
plot(seedplantstree,type="p",TRUE,label.offset=0.01,cex=0.5,no.margin=FALSE)
tiplabels(pch=21,bg=cols[ifelse(Sm.res>0,1,2)],col="black",cex=abs(Sm.res),adj=0.505)
legend("topleft",legend=c("-2","-1","0","1","2"),pch=21,
       pt.bg=cols[c(1,1,1,2,2)],bty="n",
       text.col="gray32",cex=0.8,pt.cex=c(2,1,0.1,1,2))
par(op)
```


# Phylogenetic generalized least squares (PGLS)

## Theory

Phylogenetic generalized least squares (PGLS) is just a specific application of the broader method called generalized least squares (GLS). Generalized least squares relax the assumption that the error of the model has to be uncorrelated. They allow the user to specify the structure of that residual correlation. This is used, for instance, to correct for spatial correlation, time series, or phylogenetic correlation, the topic of interest here.

GLS have the same structure as Ordinary Least Squares (OLS):

$$Y_i = \alpha + \beta X_i + \epsilon_i$$

The only difference is that the residuals are correlated with each other according to a correlation structure $\textbf{C}$:

$$\epsilon_i \sim N(0,\sigma^2\textbf{C})$$

Here, $\textbf{C}$ is a correlation matrix that describes how the residuals are correlated with each other. To be able to account for phylogenetic relationships in a PGLS, we thus need to be able to express the phylogenetic relationships in the form of a correlation matrix.

### Phylogenetic correlation structure

Phylogenetic relationships can be described using a correlation structure. Below, you have phylogenetic tree with branch lengths indicated above the branches.

```{r "phylogenetic tree example",echo=FALSE, fig.width=3, fig.height=2.5, fig.align='left'}
atree <- "(((a:0.15,b:0.15):0.4,c:0.55):0.5,(c:0.25,d:0.25):0.8);"
atree <- read.tree(text=atree)
plot(atree,no.margin=TRUE,label.offset=0.05)
edgelabels(c(0.5,0.4,0.15,0.15,0.55,0.8,0.25,0.25),adj=c(0.5,-0.5),frame="none",bg="",cex=0.7)
```

Now, this tree can be perfectly represented by a variance-covariance matrix.

``` {r "vcv of a tree", echo=FALSE}
(VCV <- vcv(atree))
```

The diagonal elements of the matrix are the species variances; these numbers represent the total distance from the root of the tree to the tips. It determines how much the tips have evolved from the root. The off-diagonal elements are the covariances between the species. They indicate the proportion of the time that the species have evolved together. This corresponds to the length of the branches that two species share, starting from the root of the tree. For instance, species $a$ and $c$ have shared a common history for 0.5 units of time; hence they have a covariance of 0.5. The greater the covariance, the longer the two species have shared the same evolutionary history.

> Note that all the tips are equidistant from the root. When trees have this property, they are said to be ***ultrametric***. Most phylogenetic comparative methods require the trees to be ultrametric, although there are sometimes ways to relax this assumption. If you do not have an ultrametric tree, it is possible to make it ultrametric using the function `chronopl` of the `ape` package, although this approach is not ideal.

The variance-covariance matric of a phylogenetic tree can be obtained from a tree using the function `vcv` from the `ape` package.

```{r "vcv function"}
# 'atree' corresponds to the phylogenetic tree shown above in newick format
atree <- "(((a:0.15,b:0.15):0.4,c:0.55):0.5,(c:0.25,d:0.25):0.8);"
# Let's now read this tree and store it as a phylogenetic tree object in R
atree <- read.tree(text=atree)
# Extract the variance-covariance matrix
varcovar <- vcv(atree)
# Print the variance-covariance matrix
varcovar
```

This is great, but we mentioned above that it is a correlation matric that we need in a GLS to account for the correlation in the residuals. To obtain a correlation matrix from the variance-covariance matrix shown above, you only need to divide the variance-covariance matrix by the length of the tree, or the distance from the root to the tips. It can also be obtained using the R function `cov2cor`.

```{r "cov2cor"}
# Convert the covariance matrix to a correlation matrix
corrmat <- cov2cor(varcovar)
# Print the matrix, rounding the numbers to three decimals
round(corrmat,3)
```

Now, the diagonal elements equal to 1, indicating that the species are perfectly correlated to themselves. Note that it is also possible to obtain directly the correlation matrix from the function `vcv` by using the `corr=TRUE` option.

```{r "vcv corr=TRUE option"}
# Obtaining a correlation matrix using the 'vcv' function
corrmat <- vcv(atree,corr=TRUE)
round(corrmat,3)
```

Now that we know how to obtain a correlation matrix from a phylogenetic tree, we are ready to run a PGLS.

## Challenge 2

Can you get the covariance matrix and the correlation matrix for the seed plants phylogenetic tree from the example above (`seedplantstree`)?

```{r "Challenge 2", echo=TRUE, eval=TRUE}
# Covariance matrix
seedplants.cov <- vcv(seedplantstree,corr=FALSE)
round(seedplants.cov,3)
# Correlation matrix
seedplants.cor <- vcv(seedplantstree,corr=TRUE)
round(seedplants.cor,3)
```


## Practicals

There are several ways to run PGLS in R. For instance, the package `caper` is a very well known package for PGLS. However, we will use the function `gls` here from the `nlme` package, which comes with the base packages in R. This function is robust and has the advantage to be very flexible. Indeed, it allows to easily use more complex models such as mixed effect models, although this will not be discussed here.

Before we run the PGLS, let's run the basic model with the function `gls` as a reference. Running the standard linear model with the package `nlme` will allow to run model comparison functions in R (see below), which would not be possible is different models were fitted using different packages.

```{r "gls reference"}
require(nlme)
shade.pgls0 <- gls(Shade ~ Wd, data = seedplantsdata)
summary(shade.pgls0)
```

You can see that the output is essentially identical to that of the `lm` function. However, there are some differences. One is the presence of the item “Correlation:” that gives the correlation among the estimated parameters. Also, the “Standardized residuals” are the raw residuals divided by the residual standard error (the raw residuals can be output with `residuals(shade.gls,"response")`).

Now, let's run a PGLS model. To assign the correlation matrix to the `gls` function, you simply need to use the `corr` option of the `gls` function. You need to pass a specific correlation function so that R can calculate the model correctly. There are several different types of correlation structures that are available in `R`. We will start by using one of the simplest one, called `corSymm`, that assumes that the correlation matrix is symmetric. This is the case with phylogenetic trees; the correlation between species $a$ and $b$ is the same as between $b$ ad $a$. Only the lower triangular part of the matrix has to be passed to the `corSymm` structure. If `mat` is the correlation matrix, this is done using the command `mat[lower.tri(mat)]`. Then you pass the correlation matrix to `gls` using the `correlation` argument.

```{r "pgls"}
# Calculate the correlation matrix from the tree
mat <- vcv(seedplantstree,corr=TRUE)
# Create the correlation structure for gls
corr.struct <- corSymm(mat[lower.tri(mat)],fixed=TRUE)
# Run the pgls
shade.pgls1 <- gls(Shade ~ Wd, data = seedplantsdata, correlation=corr.struct)
summary(shade.pgls1)
```

Note that the term `fixed=TRUE` in the corSymm structure indicates that the correlation structure is fixed during the parameter optimization.

The output is similar to that of the model without the correlation, except for the output of the correlation matrix. 

Interestingly, you can see that the coefficient estimate for the slope is greater (`r round(summary(shade.pgls1)$tTable[2,1],3)`) than with standard regression and also significant ($p$=`r round(summary(shade.pgls1)$tTable[2,4],4)`). This is a positive exmple of PGLS. Indeed, the relationship between shade tolerance and wood density was obscured by the phylogenetic correlation of the residuals. Once this correlation is accounted for, the significant relationship is revealed.

A significant relationship between shade tolerance and wood density actually make sense, even though this relationship is most likely not causal. Indeed, shade tolerant trees are generally sucessional species and often grow slower, partly because of the limited light availability, and thus tend to develop higher density woods. 

Now, let's have a look at the residuals of the model. To extract residuals corrected by the correlation structure, you need to ask for the normalized residuals.

```{r "pgls residual fit"}
# Extract the residuals corrected by the correlation structure
pgls1.res <- residuals(shade.pgls1,type="normalized")
# Change the graphical parameters
op <- par(mar=c(1,1,1,1))
# Same plotting as above except for using pgls1.res as residuals
plot(seedplantstree,type="p",TRUE,label.offset=0.01,cex=0.5,no.margin=FALSE)
tiplabels(pch=21,bg=cols[ifelse(pgls1.res>0,1,2)],col="black",cex=abs(pgls1.res),adj=0.505)
legend("topleft",legend=c("-2","-1","0","1","2"),pch=21,
       pt.bg=cols[c(1,1,1,2,2)],bty="n",
       text.col="black",cex=0.8,pt.cex=c(2,1,0.1,1,2))
# Reset graphical parameters to defaults
par(op) 
```

If you compare with the ordinary least squares optimization, the residuals are much less phylogenetically correlated.


### Other correlation structures

In the previous PGLS, we have used the corSymm structure to pass the phylogenetic correlation structure to the gls. This is perfectly fine, but there are more simple ways. Julien Dutheil has developped phylogenetic structures to be used especially in PGLS.

The one we used above is equivalent to the `corBrownian` structure of `ape`. This approach is easier and you just have to pass the tree to the correlation structure. Here is the same example using the `corBrownian` structure.

```{r "corBrownian"}
# Get the correlation structure
bm.corr <- corBrownian(phy=seedplantstree)
# PGLS
shade.pgls1b <- gls(Shade ~ Wd, data = seedplantsdata, correlation=bm.corr)
summary(shade.pgls1b)
```

You can see that the results are identical. The only difference is that the correlation structure is not outputed in the summary. The `numeric(0)` means that no parameter was estimated during the optimization (it is fixed).

Now, you might wonder why the correlation structure is called corBrownian. This is because is uses Brownian motion to model the evolution along the branch of the tree. This is often refferred as a neutral model. If you want to know more about the Brownian Motion model, you can look at the section on this model at the end of the tutorial.

## Challenge 3

Fit a PGLS model to see whether the seed mass (`Sm`) explains shade tolerance (`Shade`) with the seedplantdataset. How does it compare to the results from the standard regression.

```{r "Challenge 3", warning=FALSE, echo=TRUE, eval=TRUE}
# Fit a PGLS with the gls function
Sm.pgls <- gls(Shade ~ Sm, data = seedplantsdata, correlation=bm.corr)
# Get the results
summary(Sm.pgls)
# Extract the residuals corrected by the correlation structure
Sm.pgls.res <- residuals(Sm.pgls,type="normalized")
# Plot the residuals beside the phylogeny
op <- par(mar=c(1,1,1,1))
plot(seedplantstree,type="p",TRUE,label.offset=0.01,cex=0.5,no.margin=FALSE)
tiplabels(pch=21,bg=cols[ifelse(Sm.pgls.res>0,1,2)],col="black",cex=abs(Sm.pgls.res),adj=0.505)
legend("topleft",legend=c("-2","-1","0","1","2"),pch=21,
       pt.bg=cols[c(1,1,1,2,2)],bty="n",
       text.col="gray32",cex=0.8,pt.cex=c(2,1,0.1,1,2))
par(op)
```


# Phylogenetic Independent Contrasts

## Practicals

Let's make a digression to look at Phylogenetic Independent Contrasts (PIC). PIC were the first comparative approach proposed to deal with phylogenetic correlations (Felsenstein, 1985). Although they are less powerful than PGLS, they give the same results. Let's see how they can be used.

Phylogenetic independent contrast are estimated one trait at a time. They essentially transform the observed trait in contrasts that are not correlated with the phylogeny. This can be done in R using the `pic` function of the `ape` package.

```{r estimating_contrast}
# Estimate PIC for shade tolerance 
Shade.pic <- pic(seedplantsdata$Shade, phy=seedplantstree)
# Estimate PIC for Wood density 
Wd.pic <- pic(seedplantsdata$Wd, phy=seedplantstree)
```

Once this is done, the only thing to do is to fit a regression between these contrast. Note that it is important that the intercept is fixed to 0 in the model. This is done by adding `- 1` to the right of the formula.

```{r fitting_pic}
# Estimate PIC for shade tolerance
pic.results <- lm(Shade.pic ~ Wd.pic - 1)
summary(pic.results)
```

You can see that the slope estimate, `4.361`, it identical to the slope estimate obtained with PGLS. Same thing for the p-value. The main retriction with PIC is that you are limited in always comparing two variables. Much more flexibility is possible with PGLS.

# Relaxing the assumption that all residuals need to be phylogenetically correlated

Phylogenetic Generalized Least Squares assume that the residuals are all phylogenetically correlated. This is relatively constraining because it means that other sources of errors that are not phylogenetically correlated are not allowed by the model. Morever, if these exist, they can bias the results of the PGLS.

There are ways to relax this assumption, and one of this is to use a type of correlation structure that allows to relax this assumption.

## Theory: Pagel's correlation structure

When controling for phylogenetic relationships with phylogenetic generalized least squares, we assume that the residuals are perfectly correlated according to the correlation structure. In practice, it might not be always the case and it is difficult to really know how important it is to control for the phylogenetic relationship in a specific case. For instance, for a given study, the correlation in the residuals might not be highly phylogenetically correlated.

This is possible to account for this using the $\lambda$ model of Pagel (1999). The idea is to multiply the off-diagonal of the correlation matrix (essentially the branch lengths of the phylogeny) by a parameter $\lambda$, but not the diagonal values. This essentially leads to a modification of branch lengths of the phylogeny. A $\lambda$ value near zero gives very shorts branch lengths to the branches of the phylogenies, leaving only long tip branches. This, in effect, reduces the phylogenetic correlation (the correlations are reduced). At the opposite, if $\lambda$ is close to 1, then the modified phylogeny ressembles the true phylogeny. Indeed, the parameter $\lambda$ is often interpreted as a parameter of phylogenetic signal; as such, a greater $\lambda$ value implies a stronger phylogenetic signal.

The following figure shows how different lambda values affect the shape of the Quebec trees phylogeny.

```{r "alpha example", echo=FALSE, fig.align='center', message=FALSE}
require(geiger)
op <- par(mfrow=c(1,3))
plot(rescale(seedplantstree,model="lambda",0.1),main=expression("lambda=0.1"))
plot(rescale(seedplantstree,model="lambda",0.5),main=expression("lambda=0.5"))
plot(rescale(seedplantstree,model="lambda",1),main=expression("lambda=1"))
par(op)
```

You can see that with small values of lambda, the weight given to the shared history (the phylogeny) are greatly reduced and leaves long terminal branches on the tree. These long terminal branches can be seen as errors that are present in the estimates for each species but that are independent of the phylogeny (such as measurement errors for instance).

## Practicals

Pagel's $\lambda$ model can be used in PGLS using the `corPagel` correlation structure. The usage of this correlation structure is similar to that of the `corBrownian` structure, except that you need to provide a starting parameter value for $\lambda$.

```{r "corPagel example"}
# Get the correlation structure
pagel.corr <- corPagel(0.3, phy=seedplantstree, fixed=FALSE)
```

The value given to `corPagel` is the starting value for the $\lambda$ parameter. Also, note that the option `fixed=` is set to `FALSE` This means that the $\lambda$ parameter will be optimized using generalized least squares. If it was set to `TRUE`, then the model would be fitted with the starting parameter, here `0.3`.

Let's now fit the PGLS with this correlation structure.

```{r "Fitting PGLS with corPagel"}
# PGLS with coraPagel
shade.pgls2 <- gls(Shade ~ Wd, data = seedplantsdata, correlation=pagel.corr)
summary(shade.pgls2)
```

You can see that gls has estimated the $\lambda$ parameter, which is 0.958 here. Because the estimated $\lambda$ is very close to 1, we can conclude that residuals of the model were highly phylogenetically correlated. This, in turns, thus confirms the importance of using a PGLS with this model. If the $\lambda$ estimated would have been close to 0, it would have suggested that the PGLS is not necessary.

## Challenge 4

Try to fit a PGLS with a Pagel correlation structure when regressing Shade tolerance on seed mass. Are the residuals as phylogenetically correlated than in the previous regression with wood density?

```{r "Challenge 4", warning=FALSE, echo=TRUE, eval=TRUE}
# Fit a PGLS with the gls function
Sm.pgls2 <- gls(Shade ~ Sm, data = seedplantsdata, correlation=pagel.corr)
# Get the results
summary(Sm.pgls2)
```


## Other correlation structures (or evolutionary models)

The correlation structures available in the package `ape` offer other alternatives for the assumed model of character evolution. For instance, the `corMartins` correlation structure models selection using the Ornstein-Uhlenbeck or Hansen model with parameter $\alpha$ that determines the strength of the selection. Also, `corBlomberg` models accelerating or decelerating Brownian evolution, that is, the evolutionary rate of the Brownian motion is either accelerating or decelerating with time with this model. 


# Extending PGLS... phylogenetic ANOVA

## Practicals

The great thing with PGLS as implemented with the `gls` function is that it can easily be adapted to testing many different types of models. To give just one example here, it is easy to implement a phylogenetic ANOVA in R. Indeed, you just need to give `gls` a categorical trait as independent variable.

Because there is no categorical variable in the plant functional trait dataset, we will create one by dividing the wood density category in two categories, light and dense wood.

```{r "make categorical variable"}
# Make categorical variable
seedplantsdata$Wd.cat<-cut(seedplantsdata$Wd,breaks=2,labels=c("light","dense"))
# Look at the result
seedplantsdata$Wd.cat
```

We can now fit a phylogenetic ANOVA.

```{r "Phylogenetic ANOVA"}
# Phylogenetic ANOVA
shade.pgls3 <- gls(Shade ~ Wd.cat, data = seedplantsdata, correlation=pagel.corr)
summary(shade.pgls3)
```

You can see that the wood density, even when transformed in a categorical variable, has a significant effect on shade tolerance.


# Model testing

## Practicals

You might be interested in comparing different models, which is a common approach to modelisation in biology. However, there is a slight twist that you need to be aware of with PGLS.

The default method for model fitting with `gls` is restricted maximum likelihood estimation (REML), obtained by `method="REML"`. This is different than standard maximum likelihood estimation (ML), which can be obtained with `method="ML"`. The difference between these is complex, but suffice to say that they differ in the way the variance parameters are estimated. REML provides less biased parameter estimates and is the prefered method to report the parameter coefficients in a publication. It is also the method of choice if you want to compare models with different correlation (or variance) structures. For example, if you want to test whether a PGLS model with an optimized Pagel's $\lambda$ fits the data better than a model with no phylogenetic correlation (that is, with Pagel $\lambda=0$):

```{r "cor structure comparison"}
pagel.0 <- gls(Shade ~ Wd, data = seedplantsdata, 
               correlation=corPagel(0,phy=seedplantstree, fixed=TRUE), 
               method="REML")
pagel.fit <- gls(Shade ~ Wd, data = seedplantsdata, 
                 correlation=corPagel(0.8,phy=seedplantstree, fixed=FALSE),
                 method="REML")
anova(pagel.0,pagel.fit)
```

You can use the AIC or BIC to compare the model, or the likelihood ratio test. You can see here that the PGLS model with a fitted Pagel $\lambda$ has a better fit than the one with a $\lambda=0$. This is also a test of whether a PGLS model is better than a standard regression model.

Now, if you are interested in testing the fixed parameters in the model, you need to use maximum likelihood fitting. For instance, if you want to use a likelihood ratio test to test the model with wood density as independent variable versus a null model with just the intercept, you can do the following.

```{r "fixed effect comparison"}
wd <- gls(Shade ~ Wd, data = seedplantsdata,
          correlation=corBrownian(phy=seedplantstree), method="ML")
null <- gls(Shade ~ 1, data = seedplantsdata,
            correlation=corBrownian(phy=seedplantstree),method="ML")
anova(wd,null)
```

You can see the model with the wood density variable is better than the model with only the intercept. However, as mentionned above, because the REML fitting provides better parameter estimates, you would have to refit the model using REML to present the results.

```{r "Final fitting"}
wd.final <- gls(Shade ~ Wd, data = seedplantsdata,
                correlation=corBrownian(phy=seedplantstree), method="REML")
summary(wd.final)
```


# The Phylogenetic Mixed Model (PMM)

We mentioned previously that it is not a good idea to force all the residuals to be phylogenetically correlated and we saw that using the corPagel correlation structure provides one solution. In this section, we will see another approach that can do this, and much more. It is the phylogenetic mixed model.

## Theory

### Mixed Models

As the name says, the phylogenetic mixed model is a mixed model. That is, it can be composed of fixed or random effects. Fixed effects are generally the variable of interest in an experiment; their effect on the response variable need to be quantified precisely. In contrast, the random effects in a model are variables that we now can affect the response variable but for which we are not specifically interested in quantifying their effects on the response variable. A good example of random effect is that of blocks in a replicated experiments. We often repeat experiments in blocks to account for spatial effects for instance. In such cases, blocks can be included as a random effect in the model to account for this additional variance that was accounted for. However, we are not interested in this variation per see.

This is very similar to the problem of phylogenetic correlations. Indeed, we know that the phylogenetic relationships between species can affect the relationship between variables and we can describe the correlation structure. However, we are not really interested in the effect of the phylogenetic correlations on the response variable (note that sometimes we are, such as when we want to estimate the phylogenetic signal in a variable); we just want to account for it in the main statistical test. As you can see, the phylogenetic correlations thus fits very well the definition of a random effect in a mixed model.

### The Phylogenetic Mixed Model (PMM)

The phylogenetic mixed model was first proposed by Lynch in 1991. This model was borrowed from quantitative genetic where similar models (generally called the 'animal' model) have been used from quite some time. It made a comeback in 2004 when Housworth et al. (2004) proposed efficient algorithms to implement it. But it is really following the publication of the MCMCglmm package (Hadfield and Hasagawa, 2010) that Phylogenetic Mixed Model could be applied widely by biologists.

The phylogenetic mixed model has been described in detail elsewhere (Hadfield et al. 2010, Villemereuil 2014) and this description will be rather brief. In the following, lowercase italic letters represent numbers, lowercase boldface letters vectors and uppercase boldface letters matrices. The phylogenetic mixed model (PMM) has the form:

$$
\textbf{y} = \mu + \beta \textbf{x} + \textbf{a} + \textbf{e},
$$

where $\textbf{y}$ is the response variable, $\mu$ is the intercept, $\textbf{x}$ is an explanatory variable, $\beta$ the regression coefficient, $\textbf{a}$ represents the effects due to the phylogenetic structure, and $\textbf{e}$ the residuals. $\textbf{x}$ is a fixed effect (there could be more than one), whereas $\textbf{a}$ is a random effect. The random effect and residuals are assumed to follow normal distributions:

$$
  \textbf{a} \sim \mathcal{N}(0,\sigma_a^2 \textbf{A}) \\
  \textbf{e} \sim \mathcal{N}(0,\sigma_{e}^2 \textbf{I}).
$$


$\sigma_a^2$ is the phylogenetic variance and $\sigma_e^2$ is the residual variance. The matrix $\textbf{A}$ represents the phylogenetic correlation structure. The identity matrix $\textbf{I}$ indicates that the residuals are independent and identically distributed. Accordingly, the (co)variance structure ($\textbf{V}$) of the model is $\textbf{V}=\sigma_a^2 \textbf{A} + \sigma_{e}^2 \textbf{I}$.

The major difference with PGLS is the great flexibility. For instance, the residuals are not expected to be all phylogenetically correlated. Indeed, the residuals ($\textbf{e}$) are explicitely quantified in the model. Moreover, it is possible to add many more random effects. For instance, one could add a random affect that can account for a block design, or for measurement errors (if the response variable is estimated several times). This is simply not possible with PGLS.

Similarly with the PGLS and the estimation of the $\lambda$ parameter with the corPagel structure, it is possible to estimate the pylogenetic signal with the PMM. The idea is to estimate the proportion of the total variance ($\sigma^2=\sigma_a^2 + \sigma_{e}^2$) that is due to the genetic structure; this is the heritability ($h^2$) parameter of quantitative geneticists (Housworth et al. 2006). The heritability is the quotient obtained by dividing the phylogenetic variances by the total variance: $h^2 = \sigma_a^2 / \sigma^2$. The remaining variance, $1-h^2=\sigma_e^2/\sigma^2$, is the non-genetic variance that could be due to the environment or other effects that impact the individuals in a way that is not defined by the genetic correlation structures.

For this reason, the PMM is more interesting than PGLS. Yet, PGLS continues to be widely used. One reason for this is that PMM are still poorly known. The other is that the statistical tools are a bit complex. The main open source package to perform PMM (MCMCglmm) implements Bayesian models and can be quite complicated. However, as we will see here, it is realitively easy to perform simple analyses.


## Practicals

### Prepare dataset

To show the usefulness of the PMM, we will use a different dataset. This dataset  is from a climate warming experiment from [Joly, Flynn and Wolkovich (2005)](https://doi.org/10.1111/2041-210X.13184).

Briefly, ten species/shrubs were sampled from two locations: the Station de biologie des Laurentides (St. Hypplolite, QC) and the Harvard Forest (MA, USA). Tree clippings were collected during the winter and were kept in cold. The clipping were then subjected to different warming and photoperiod treatments and the number of days before the buds open (budburst) was recorded. We also have a phylogenetic tree for the species included in the analysis.

Let's first load the data:

```{r "Load budburst data"}
# Load the datasets and phylogeny
load("./data/budburst.Rdata")
```

There are two files. 

1. `thedata` contains the budburst data. It contains the species information (`species`), the time to budburst (`days`), the warming treatment (`temperature`), the photoperiod treatment (`photoperiod`).
1. `treephylo` contains the phylogenetic tree

Let's look at these files:

```{r "budburst files"}
# The dataset
head(thedata,n=8)
# The phylogeny
treephylo
```

The next step is to format the data for the PMM analysis. The first step is to name the column of the dataset that contain the species names (those that appear on the phylogeny) 'animal'. This is a prerequisite of MCMCglmm. 

```{r "Name column animal"}
# Rename the column with species code "animal". This is required for MCMCglmm
colnames(thedata)[1] <- "animal"
```


### Run MCMCglmm

Now that the data is loaded, we are ready to run MCMCglmm. We will run two models: Model `m0` that does not have random effects (i.e., that does not account for the phylogenetic relationships) and mode `m1` that corrects for the phylogeny.

But before we can run the model, we need to give priors to the fixed and random effects. We will use uninformative priors, which means that it does not give high a priori weights to any specific value. This is often a good starting point.

```{r "priors", warning=FALSE}
# Load MCMCglmm
library(MCMCglmm)
# Prior for model m0 is only for fixed effects (R).
prior.m0 <- list(R = list(V = 1, nu = 0.002))
# Prior for model m1 is for fixed effects (R) and random effects (G).
prior.m1 <- list(R = list(V = 1, nu = 0.002), 
                   G = list(G1 = list(V = 1, nu = 0.002)))
```

We can then run the analyses. In these analyses, we will include as fixed variable the temperature, the photoperiod, and their interaction.

In a Bayesian Markov Chain Monte Carlo (MCMC) analysis, you need to provide the number of generations the MCMC chain will do (`nitt` in the MCMCglmm function), the interval at which the parameters will be sampled (`thin`) and the number of generations to discard at the beginning of the search (`burnin`). Removing the first generations is often important because the paramters in these generations are generally very poor because the chain has not yet reached the higher likelihood regions of the parameter space.

```{r "MCMCglmm runs",eval=FALSE}
# Model m0
m0 <- MCMCglmm(days ~ temperature * photoperiod, data=thedata, scale=TRUE,
               nitt=55000,thin=20,burnin=5000,prior=prior.m0)
# Model m1
m1 <- MCMCglmm(days ~ temperature * photoperiod, random = ~ animal, pedigree = treephylo,
               data=thedata, scale=TRUE,nitt=55000,thin=20,burnin=5000,prior=prior.m1)
```

```{r "load results",echo=FALSE}
#save(m0,m1,m1b,file="./data/model_fit.Rdata")
load(file="./data/model_fit.Rdata")
```

### Model comparison

Now that we ran the models, we can compare the different models using the Deviance Information Criterion (DIC; lower values are best). The Deviance Information Criterion is similar to the AIC, but for Bayesian analyses.

```{r "model fit"}
# Compare fit of the models (deviance information criterion)
data.frame(models=c("m0","m1"), DIC=c(m0$DIC,m1$DIC))
```

It is clear from these results that the m1 model is much better as it has a smaller DIC value. Note that DIC are known to be somewhat inccurate. Therefore, they should not be the sole reason for favouring a model versus another. Inspection of parameter estimates can also be very informative.

### Run convergence

Before looking at this model more closely, it is important to look at the convergence of the MCMC run. To evaluate this, it is useful to run an independent analysis.

```{r "second run", eval=FALSE}
# Do another run to check for convergence
m1b <- MCMCglmm(days ~ temperature * photoperiod, random = ~ animal, pedigree=treephylo,
               data=thedata, scale=TRUE,nitt=55000,thin=20,burnin=5000,prior=prior.m1)
```

Once this is done, we can calculate the Potential Scale Reduction Factors (PRSF) for the random effects. This compares the variance between runs vs. the variance within runs. The value converges towards 1 with increasing convergence (iter variance = intra variance). Generally, a PRSF value < 1.05 is considered relatively good.

```{r gelman}
# Potential scale reduction factors (PSRF)

# PSRF of fixed effects
gelman.diag(mcmc.list(m1$Sol,m1b$Sol))
# PSRF of random effects
gelman.diag(mcmc.list(m1$VCV,m1b$VCV))
```

You can see that these are very close to 1, suggesting very good convergence. This is also evident when looking at the plot of the values generation per generation as the mixing is very good.

```{r mixing}
# look at MCMC chain sampling
plot(mcmc.list(m1$VCV,m1b$VCV))
```

### Model summary

Now that we are convinced that the analyses have converged, we can look at the results summary (here from a single run).

```{r "m1 model summary"}
# Summary of best model
summary(m1)
```

The effective sample sizes (corrected for the autocorrelation along the chain) are all relatively good, both for random and fixed effects.

For the **fixed effects**, the model suggests that temperature and the photoperiod are highly significant. The interaction between the temperature and the photoperiod (`warm:photo`) is also significant.

We can also visualize the fixed effects using a figure.

```{r "Fixed effects graph", fig.height=3, fig.width=5, fig.align='center', echo=FALSE}
library(ggplot2)
#Fixed effects
results.m1 <- as.data.frame(summary(m1)$solutions)
results.m1$effects <- factor(rownames(results.m1),levels=rownames(results.m1))
colnames(results.m1)[2:3] <- c("lowerCI","upperCI")
fixed.p <- ggplot(results.m1[-1,], aes(y=post.mean, x=effects)) + 
  geom_point(color="black") +
  geom_linerange(aes(ymin=lowerCI, ymax=upperCI)) + 
  geom_hline(yintercept = 0, lty=3) +
  scale_x_discrete(limits = rev(levels(results.m1$effects)[-1])) +
  ylab("Change in number of day for budburst") + xlab("") +
  coord_flip() + theme_light()
fixed.p
```

The results show that an increase in temperature of 5 C resulted in a budburst 20 days earlier. Similarly, an increase of photoperiod of 4 hours resulted in a budburst 12 days earlier. The significant positive interaction shows that these two reactions are not completely additive; the budburst with both increase in temperature and photoperiod is 5 days later than if you would simply add the effects of temperature and photoperiod.

Let's now look at the **random effects**. To evaluate variance explained by the random effects, it is useful to look at the relative proportion of the variance explained by each effect and by the residuals (`units`):

```{r variance}
# Proportion of variance explained by random factors

# This will calculate the relative variance due to the phylogenetic
#  effects for all generations of the run
rand <- m1$VCV/apply(m1$VCV,1,sum)
# We can then calculate the mean relative variance
apply(rand,2,mean)
```

The phylogenetic component explains 66% of the total variation. This correspond to the phylogenetic signal of the "residual" variation. It is very high and illustrate the important to take these relationships into account.

As a comparison, we can look at the results when the phylogenetic relationships are ignored.

```{r "Null model"}
summary(m0)
```

You can see that the results for the fixed effects are similar, but that the effect sizes have diminished. But more importantly, the interaction is not significant anymore.

This is another positive example of the use of comparative methods. The variance due to the phylogenetic effects contributed in masking the fixed effects. Once it is taken into account, the fixed effects can be more accurately estimated.


## Challenge 5

Apply a PMM to the seed plant data to study the relationship between wood density and shade tolerance. Do the results vary much between the PMM and the PGLS approaches? The first step is to create an animal column from the rownames so that the phylogeny can be associated to the dataset:

```{r "Challenge 5 - preliminary steps"}
# Prepare the data for MCMCglmm
seedplantsdata$animal <- rownames(seedplantsdata)
```

Try to do the other steps by yourself.

```{r "Challenge 5", eval=TRUE, echo=TRUE}
# Load MCMCglmm
library(MCMCglmm)


#
# Priors

# Prior for model shade.m0 is only for fixed effects (R).
prior.shade.m0 <- list(R = list(V = 1, nu = 0.002))
# Prior for model shade.m1 is for fixed effects (R) and random effects (G).
prior.shade.m1 <- list(R = list(V = 1, nu = 0.002), 
                   G = list(G1 = list(V = 1, nu = 0.002)))


#
# Model fitting

# Model shade.m0
shade.m0 <- MCMCglmm(Shade ~ Wd, data=seedplantsdata, scale=TRUE,
               nitt=55000,thin=20,burnin=5000,prior=prior.shade.m0)
# Model shade.m1
shade.m1 <- MCMCglmm(Shade ~ Wd, random = ~ animal, 
               pedigree = seedplantstree, data=seedplantsdata, scale=TRUE,
               nitt=55000,thin=20,burnin=5000,prior=prior.shade.m1)

# Compare fit of the models (deviance information criterion)
data.frame(models=c("shade.m0","shade.m1"),
           DIC=c(shade.m0$DIC,shade.m1$DIC))


#
# Run convergence

# Do another run to check for convergence
shade.m1b <- MCMCglmm(Shade ~ Wd, random = ~ animal, 
               pedigree = seedplantstree, data=seedplantsdata, scale=TRUE,
               nitt=55000,thin=20,burnin=5000,prior=prior.shade.m1)

# PSRF of fixed effects
gelman.diag(mcmc.list(shade.m1$Sol,shade.m1b$Sol))

# PSRF of random effects
gelman.diag(mcmc.list(shade.m1$VCV,shade.m1b$VCV))


#
# Summary of best model

summary(shade.m1)


#
# Heredity (i.e., phygenetic signal)

# Proportion of variance explained by random factors
rand <- shade.m1$VCV/apply(shade.m1$VCV,1,sum)
apply(rand,2,mean)
```


# When should we use comparative methods?

Comparative methods should always be used when working with datasets that comprise multiple species. A good advice though is to use a method that allows the residuals of the model not to be all phylogenetically correlated, as when using the PGLS with the corPagelstructure or using the Phylogenetic Mixed Model. Previous strudies have shown that using such comparative methods results in more precise and accurate fixed effect estimation, lower type I error, and greater statistical power. Therefore, it is always advantageous to use these methods.

A common mistake made when someone considers to use PGLS is to test for phylogenetic signal in $Y$ or $X$ using either Pagel's $\lambda$ or Blomberg's $K$, and if they observe some phylogenetic signal, they use a PGLS to analyse their data. This is a ***big mistake***. As we saw earlier, PGLS corrects for phylogenetic correlation in the residuals and not in the variables. Therefore, the presence of phylogenetic signal in the variables does not necessarily mean that the residuals are phylogenetically correlated.

Another common misconception of comparative methods is that it removes all variation in the data related to the phylogeny and that this could affect the interpretation of the variable of interest. This was true of old methods like phylogenetic autoregression that first removed the phylogenetic signal from the data before analysing them. These approaches were indeed problematic. But the methods presented here to not suffer from these problems. They account for the phylogenetic structure and quantify it, but it does not removes variation from the model.


# Appendix 1: The Brownian Motion (BM) model

When we want to account for the non-independence of species due to their evolutionary histories in statistical analyses, a model of evolution is necessarily implied. Indeed, we assume that traits evolved through time (along the phylogeny) and that closely related species are more likely to be more similar on average at a given trait than distantly related species. In evolutionary biologogy, the more basic model (often used as a null model in many analyses) is the Brownian motion model. This model of evolution is named after Robert Brown, a celeb botanist that published an important Flora of Australia in 1810. He was also the first to distinguish gymnosperms from angiosperms. His discovery of the Brownian motion is due to the observation that small particules in solution have the tendency to move in any direction, an observation first made while observing *Clarkia* pollen under a microscope. The explanation would come later, in terms of random molecular impacts.

Mathematicians have constructed a stochastic process that is intended to approximate the Brownian motion. In this model, each step is independent from the others and can go in any direction. The mean displacement is zero and the variance is uniform across the parameter space. The displacements can be summed, which means that the variances of the independent displacements can be added up. If $\sigma^2$ is the variance of a single displacement, the variance after time $t$ will be $\sigma^2t$. When the number of steps is large, as in a phylogenetic context, the result is normally distributed.

When applied to phylogenies, the Brownian motion model is kind of applied indepenpenty to each branch of the phylogeny. That allows to model the amount of change that occured along a given branch. If the variance of the Brownian motion model is $\sigma^2$ per unit of time $t$, then the net change along a branch of time $t$ is drawn from a normal distribution with mean $0$ and variance $\sigma^2t$. This model can also be represented mathematically the following way, such as the amount of change for character $X$ over the infinitesimal time in the interval between time $t$ and $t+dt$ is:

$$dX(t)=\sigma^2 dB(t),$$

where $dB(t)$ is the gaussian distribution. Importantly, this model assumes that:

1. Evolution occuring in each branch of the phylogeny is independent of that occuring in other branches.
2. Evolution is completely random (i.e., no selection).

The parameter $\sigma^2$ in the model gives the variance, or in other word the speed of evolution. The higher the variance, the faster the character will evolve. Here are two examples of simulated characters on a tree of 200 species with $\sigma^2=0.5$ and $\sigma^2=4$.

```{r "BM_Model_SigmaExample", echo=FALSE, fig.height=3, fig.width=5, message=FALSE, warning=FALSE, fig.align='center'}
library(phytools)
library(ggplot2)
tree<-pbtree(n=200)
x<-fastBM(tree,sig2=0.5) # sigma = 0.5
y<-fastBM(tree,sig2=4) # with a trend
data<-data.frame(sigma=rep(c(0.5,4),each=200),values=c(x,y))
ggplot(data,aes(x=values),y=as.factor(sigma))+geom_histogram() +
  facet_wrap(~sigma)
rm(data,x,y)
```

A more thorough introduction to the Brownian Motion model can be found in Felsenstein (2004, chapter 23).

The Brownian motion model is often said to model neutral drift, although a good fit to this model does not necessarily means that the data evolved via random drifts as other processes can also result in BM-like patterns (Hansen and Martins, 1996).

Note also that the model is stochastic. That is, even if two closely related species are more likely to share similar character states than a distant one, this is only true on average. For any given simulated character, closely related species can sometimes be more different than to a distant species. Look at the following figure, that shows three traits simulated under the Brownian motion.

```{r "PlotContinuousParameter_tablephylo4d", echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
require(phytools)
set.seed(667)
tree <- pbtree(n=30,nsim=1)
trait1 <- fastBM(tree, sig2=0.15, nsim=1, internal=FALSE)
trait2 <- fastBM(tree, sig2=0.1, nsim=1, internal=FALSE)
trait3 <- fastBM(tree, sig2=0.15, nsim=1, internal=FALSE)
op <- par(mar=c(1,1,1,1))
plot(tree,type="p",TRUE,label.offset=1,cex=0.5,no.margin=FALSE)
tiplabels(pch=21,bg=cols[ifelse(trait1>0,1,2)],col="black",cex=abs(trait1)*2,adj=0.75)
tiplabels(pch=21,bg=cols[ifelse(trait2>0,1,2)],col="black",cex=abs(trait2)*2,adj=1)
tiplabels(pch=21,bg=cols[ifelse(trait3>0,1,2)],col="black",cex=abs(trait3)*2,adj=1.25)
legend("bottomleft",legend=c("-4","-2","0","2","4"),pch=21,
       pt.bg=cols[c(1,1,1,2,2)],bty="n",
       text.col="gray32",cex=0.8,pt.cex=c(2,1,0.1,1,2))
par(op) 
```


# Further readings

To undertand well a new research field, it is always advisable to read a lot on it. Here are some references that you might find useful. The different sources also sometimes explain the theory in different ways or use different examples, which might help you understand better.

- Felsenstein, J. (1985) Phylogenies and the comparative method. *The American Naturalist* 125, 1-15. **The classic initial paper that launched the field of comparative analyses. The phylogenetic independent contrasts are introduced here**
- Felsenstein, J. (2004) *Inferring phylogenies*. Sinauer Associates, Inc. Sunderland, MA. **A thorough reference on phylogenies, from reconstruction to phylogenetic methods**
- Hadfield, J. D., S. Nakagawa. 2010. General quantitative genetic methods for comparative biology: phylogenies, taxonomies and multi-trait models for continuous and categorical characters. *Journal of Evolutionary Biology* 23:494–508. **This paper describes the phylogenetic mixed model and its implementation in MCMCglmm. It is a very important paper**
- Housworth, E.A., E.P. Martins, M. Lynch. 2004. The phylogenetic mixed model. *The American Naturalist* 163:84–96. **Excellent paper on the Phylogenetic Mixed Model**
- Paradis, E. (2012). *Analysis of phylogenetics and evolution with R*. New York, USA: Springer. **This is the book that explains the analyses available in the R package APE. It is also a great reference on many phylogenetic analyses, including the comparative method. This is a classic and a must for users of phylogenies in R.**
- Revell, L J. (2010). Phylogenetic signal and linear regression on species data. *Methods in Ecology and Evolution* 1: 319-329. **A great paper on PGLS. It uses simulations to show when it is important to use PGLS.**
- Villemereuil, P., S. Nakagawa. 2014. General quantitative genetic methods for comparative biology. Pp. 287–303 in L. Z. Garamszegi, ed. *Modern phylogenetic comparative methods and their application in evolutionary biology*. Springer-Verlag, Berlin, Heidelberg. **Nice book chapter explaining the phylogenetic mixed model**
- Zuur, A.F., E.N. Ieno, N. Walker, A. A. Saveliev, G.M. Smith. (2009). *Mixed effects models and extensions in ecology with R*. New York, NY: Springer New York. **This is not a book on phylogenetic methods, but it is a great book on the analysis of ecological data with examples in R. Its chapter 6 and 7 discuss correlation structures and although they are not about phylogenies, they are very instructive on how to deal with them and how to compare models and analyse complex data. It also has tons of information on how to deal with more complex data, along with correlation structure. A very good read!**


# References

Felsenstein, J. (1985) Phylogenies and the comparative method. *The American Naturalist* 125: 1-15.

Felsenstein, J. (2004) *Inferring phylogenies*. Sinauer Associates, Inc. Sunderland, MA. 

Hadfield, J. D., S. Nakagawa. 2010. General quantitative genetic methods for comparative biology: phylogenies, taxonomies and multi-trait models for continuous and categorical characters. *Journal of Evolutionary Biology* 23:494–508.

Hansen, T. F., E. P. Martins. (1996). Translating between microevolutionary process and macroevolutionary patterns: the correlation structure of interspecific data. *Evolution*. 50: 1404–1417.

Housworth, E.A., E.P. Martins, M. Lynch. 2004. The phylogenetic mixed model. *The American Naturalist* 163:84–96.

Paradis, E. (2012). *Analysis of phylogenetics and evolution with R*. New York, USA: Springer.

Revell, L J. (2010). Phylogenetic signal and linear regression on species data. *Methods in Ecology and Evolution* 1: 319-329.

Rohlf, F.J. (2001). Comparative Methods for the Analysis of Continuous Variables: Geometric Interpretations. *Evolution* 55: 2143-2160

Villemereuil, P., S. Nakagawa. 2014. General quantitative genetic methods for comparative biology. Pp. 287–303 in L. Z. Garamszegi, ed. *Modern phylogenetic comparative methods and their application in evolutionary biology*. Springer-Verlag, Berlin, Heidelberg.

Zuur, A.F., E.N. Ieno, G.M. Smith. (2007) *Analysing Ecological Data*. Springer. 680 p.

Zuur, A.F., E.N. Ieno, N. Walker, A. A. Saveliev, G.M. Smith. (2009). *Mixed effects models and extensions in ecology with R*. New York, NY: Springer New York.


-----
